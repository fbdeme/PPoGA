"""
PPoGA Executor Module

PPoGAì˜ ì‹¤í–‰ê°€(Executor) ì—­í• ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆìž…ë‹ˆë‹¤.
ì‹¤ì œ ì§€ì‹ ê·¸ëž˜í”„ì™€ì˜ ìƒí˜¸ìž‘ìš©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import sys
import os
from typing import Dict, List, Any, Tuple

# PoG ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'PoG'))

from ppoga_memory import PPoGAMemory

try:
    from freebase_func import entity_search, relation_search_prune
    from utils import run_llm
except ImportError:
    print("Warning: Could not import PoG modules. Mock functions will be used.")
    
    def entity_search(entity_id, relation, is_head=True):
        """Mock function for entity search"""
        return [f"mock_entity_{i}" for i in range(3)]
    
    def relation_search_prune(entity_id, sub_questions, entity_name, pre_relations, pre_head, question, args):
        """Mock function for relation search"""
        return [{"relation": "mock.relation", "entity": entity_id, "head": True}], {"total": 0, "input": 0, "output": 0}


class PPoGAExecutor:
    """
    PPoGAì˜ ì‹¤í–‰ê°€(Executor) í´ëž˜ìŠ¤
    
    ì£¼ìš” ì—­í• :
    1. ì§€ì‹ ê·¸ëž˜í”„ ì¿¼ë¦¬ ì‹¤í–‰
    2. ê²°ê³¼ ì •ì œ ë° ìš”ì•½
    3. Plannerì™€ì˜ í˜‘ì—…
    """
    
    def __init__(self, kg_config: Dict[str, Any]):
        """
        Executor ì´ˆê¸°í™”
        
        Args:
            kg_config: ì§€ì‹ ê·¸ëž˜í”„ ì„¤ì •
        """
        self.kg_config = kg_config
        self.query_count = 0
    
    def execute_step(self, entity_id: str, entity_name: str, selected_relations: List[str], 
                    current_step_description: str, memory: PPoGAMemory) -> Tuple[str, Dict[str, Any]]:
        """
        ê³„íš ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì—¬ ì§€ì‹ ê·¸ëž˜í”„ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            entity_id: íƒìƒ‰í•  ì—”í‹°í‹° ID
            entity_name: ì—”í‹°í‹° ì´ë¦„
            selected_relations: Plannerê°€ ì„ íƒí•œ ê´€ê³„ ëª©ë¡
            current_step_description: í˜„ìž¬ ê³„íš ë‹¨ê³„ ì„¤ëª…
            memory: PPoGA ë©”ëª¨ë¦¬ ê°ì²´
            
        Returns:
            Tuple[str, Dict[str, Any]]: (ê´€ì°° ê²°ê³¼, ì‹¤í–‰ ì •ë³´)
        """
        print(f"ðŸ¤– Executor: {entity_name}ì— ëŒ€í•´ {len(selected_relations)}ê°œ ê´€ê³„ íƒìƒ‰ ì¤‘...")
        
        all_results = {}
        total_entities_found = 0
        execution_info = {
            "entity_id": entity_id,
            "entity_name": entity_name,
            "relations_explored": selected_relations,
            "query_count": 0,
            "sparql_queries": []
        }
        
        # ê° ì„ íƒëœ ê´€ê³„ì— ëŒ€í•´ íƒìƒ‰ ìˆ˜í–‰
        for relation in selected_relations:
            try:
                print(f"   ðŸ” ê´€ê³„ '{relation}' íƒìƒ‰ ì¤‘...")
                
                # PoGì˜ entity_search í•¨ìˆ˜ ì‚¬ìš©
                found_entities = entity_search(entity_id, relation, True)  # head=Trueë¡œ ê°€ì •
                
                if found_entities:
                    all_results[relation] = found_entities
                    total_entities_found += len(found_entities)
                    print(f"      âœ… {len(found_entities)}ê°œ ì—”í‹°í‹° ë°œê²¬")
                else:
                    print(f"      âŒ ì—”í‹°í‹° ì—†ìŒ")
                
                execution_info["query_count"] += 1
                execution_info["sparql_queries"].append({
                    "relation": relation,
                    "entity": entity_id,
                    "result_count": len(found_entities) if found_entities else 0
                })
                
            except Exception as e:
                print(f"      âš ï¸ ê´€ê³„ '{relation}' íƒìƒ‰ ì˜¤ë¥˜: {e}")
                all_results[relation] = []
        
        # ê²°ê³¼ ìš”ì•½ ìƒì„±
        observation = self._create_observation_summary(
            entity_name, selected_relations, all_results, current_step_description
        )
        
        # ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        self._update_memory_with_results(memory, entity_id, all_results, execution_info)
        
        self.query_count += execution_info["query_count"]
        
        print(f"âœ… Executor: ì‹¤í–‰ ì™„ë£Œ - ì´ {total_entities_found}ê°œ ì—”í‹°í‹° ë°œê²¬")
        
        return observation, execution_info
    
    def _create_observation_summary(self, entity_name: str, relations: List[str], 
                                  results: Dict[str, List[str]], step_description: str) -> str:
        """
        ì‹¤í–‰ ê²°ê³¼ë¥¼ Plannerê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
        
        Args:
            entity_name: ì—”í‹°í‹° ì´ë¦„
            relations: íƒìƒ‰í•œ ê´€ê³„ë“¤
            results: ê´€ê³„ë³„ ê²°ê³¼
            step_description: í˜„ìž¬ ë‹¨ê³„ ì„¤ëª…
            
        Returns:
            str: ìš”ì•½ëœ ê´€ì°° ê²°ê³¼
        """
        total_entities = sum(len(entities) for entities in results.values())
        
        if total_entities == 0:
            return f"{entity_name}ì—ì„œ {len(relations)}ê°œ ê´€ê³„ë¥¼ íƒìƒ‰í–ˆì§€ë§Œ ê´€ë ¨ ì—”í‹°í‹°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        summary_parts = [f"{entity_name}ì—ì„œ ì´ {total_entities}ê°œì˜ ê´€ë ¨ ì—”í‹°í‹°ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤."]
        
        for relation, entities in results.items():
            if entities:
                entity_sample = entities[:3]  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                more_text = f" ì™¸ {len(entities)-3}ê°œ" if len(entities) > 3 else ""
                summary_parts.append(f"- {relation}: {', '.join(entity_sample)}{more_text}")
        
        return " ".join(summary_parts)
    
    def _update_memory_with_results(self, memory: PPoGAMemory, entity_id: str, 
                                  results: Dict[str, List[str]], execution_info: Dict[str, Any]) -> None:
        """
        ì‹¤í–‰ ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        Args:
            memory: PPoGA ë©”ëª¨ë¦¬ ê°ì²´
            entity_id: íƒìƒ‰í•œ ì—”í‹°í‹° ID
            results: íƒìƒ‰ ê²°ê³¼
            execution_info: ì‹¤í–‰ ì •ë³´
        """
        # ì§€ì‹ ê·¸ëž˜í”„ ë…¸ë“œ ë° ì—£ì§€ ì—…ë°ì´íŠ¸
        nodes = {}
        edges = {}
        
        # í˜„ìž¬ ì—”í‹°í‹°ë¥¼ ë…¸ë“œë¡œ ì¶”ê°€
        nodes[entity_id] = {
            "name": execution_info["entity_name"],
            "explored": True,
            "timestamp": execution_info.get("timestamp", "")
        }
        
        # ë°œê²¬ëœ ì—”í‹°í‹°ë“¤ì„ ë…¸ë“œì™€ ì—£ì§€ë¡œ ì¶”ê°€
        for relation, entities in results.items():
            for entity in entities:
                # ìƒˆë¡œìš´ ì—”í‹°í‹°ë¥¼ ë…¸ë“œë¡œ ì¶”ê°€
                nodes[entity] = {
                    "name": entity,
                    "explored": False,
                    "discovered_via": relation
                }
                
                # ì—£ì§€ ì¶”ê°€
                edge_key = f"{entity_id}-{relation}-{entity}"
                edges[edge_key] = {
                    "source": entity_id,
                    "relation": relation,
                    "target": entity,
                    "timestamp": execution_info.get("timestamp", "")
                }
        
        memory.update_knowledge_graph(nodes, edges)
        
        # í›„ë³´ ì—”í‹°í‹° ì¶”ê°€
        current_step_id = memory.execution["current_step_id"]
        all_discovered_entities = []
        for entities in results.values():
            all_discovered_entities.extend(entities)
        
        if all_discovered_entities:
            memory.add_candidate_entities(current_step_id, all_discovered_entities)
    
    def get_available_relations(self, entity_id: str, entity_name: str, 
                              question: str, sub_questions: List[str]) -> List[str]:
        """
        ì—”í‹°í‹°ì— ëŒ€í•´ ì‚¬ìš© ê°€ëŠ¥í•œ ê´€ê³„ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            entity_id: ì—”í‹°í‹° ID
            entity_name: ì—”í‹°í‹° ì´ë¦„
            question: ì›ëž˜ ì§ˆë¬¸
            sub_questions: í•˜ìœ„ ì§ˆë¬¸ë“¤
            
        Returns:
            List[str]: ì‚¬ìš© ê°€ëŠ¥í•œ ê´€ê³„ ëª©ë¡
        """
        try:
            # PoGì˜ relation_search_prune í•¨ìˆ˜ ì‚¬ìš©
            # ìž„ì‹œ args ê°ì²´ ìƒì„±
            class TempArgs:
                def __init__(self):
                    self.LLM_type = "gpt-3.5-turbo"
                    self.opeani_api_keys = ""
                    self.temperature_exploration = 0.3
                    self.max_length = 2048
            
            args = TempArgs()
            
            relations_data, token_info = relation_search_prune(
                entity_id, sub_questions, entity_name, [], -1, question, args
            )
            
            # ê´€ê³„ ëª©ë¡ ì¶”ì¶œ
            relations = [rel_data["relation"] for rel_data in relations_data if "relation" in rel_data]
            
            print(f"ðŸ” Executor: {entity_name}ì— ëŒ€í•´ {len(relations)}ê°œ ê´€ê³„ ë°œê²¬")
            
            return relations
            
        except Exception as e:
            print(f"âš ï¸ Executor: ê´€ê³„ íƒìƒ‰ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ê´€ê³„ ëª©ë¡ ë°˜í™˜
            return ["type.object.type", "common.topic.notable_types"]
    
    def get_execution_stats(self) -> Dict[str, Any]:
        """
        ì‹¤í–‰ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            Dict[str, Any]: ì‹¤í–‰ í†µê³„
        """
        return {
            "total_queries": self.query_count,
            "kg_config": self.kg_config
        }
