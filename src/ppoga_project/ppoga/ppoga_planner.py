"""
PPoGA Planner Module

PPoGAì˜ ì „ëµê°€(Planner) ì—­í• ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
ê³„íš ìˆ˜ë¦½, ì˜ˆì¸¡, ì‚¬ê³ , í‰ê°€, ìê¸° êµì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import json
import sys
import os
from typing import Dict, List, Any, Optional, Tuple

# PoG ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'PoG'))

from ppoga_memory import PPoGAMemory, PlanStep
from ppoga_prompts import DECOMPOSE_PLAN_PROMPT, PREDICT_PROMPT, FINAL_ANSWER_PROMPT

try:
    from utils import run_llm, extract_reason_and_anwer
    from prompt_list import extract_relation_prompt
except ImportError:
    print("Warning: Could not import PoG modules. Some functions may not work.")


class PPoGAPlanner:
    """
    PPoGAì˜ ì „ëµê°€(Planner) í´ë˜ìŠ¤
    
    ì£¼ìš” ì—­í• :
    1. ê³„íš ìˆ˜ë¦½ (Planning)
    2. ì˜ˆì¸¡ (Prediction) 
    3. ì‚¬ê³  ë° í‰ê°€ (Thinking & Evaluation)
    4. ìê¸° êµì • (Self-Correction)
    """
    
    def __init__(self, llm_config: Dict[str, Any]):
        """
        Planner ì´ˆê¸°í™”
        
        Args:
            llm_config: LLM ì„¤ì • (model, temperature, api_key ë“±)
        """
        self.llm_config = llm_config
        self.model = llm_config.get("model", "gpt-3.5-turbo")
        self.temperature = llm_config.get("temperature", 0.3)
        self.max_tokens = llm_config.get("max_tokens", 2048)
        self.api_key = llm_config.get("api_key", "")
    
    def _call_llm(self, prompt: str, temperature: Optional[float] = None) -> Tuple[str, Dict[str, int]]:
        """LLMì„ í˜¸ì¶œí•˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ"""
        temp = temperature if temperature is not None else self.temperature
        
        try:
            return run_llm(
                prompt=prompt,
                temperature=temp,
                max_tokens=self.max_tokens,
                opeani_api_keys=self.api_key,
                engine=self.model,
                print_in=False,
                print_out=False
            )
        except Exception as e:
            print(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return f"Error: {str(e)}", {"total": 0, "input": 0, "output": 0}
    
    def plan(self, question: str, memory: PPoGAMemory) -> bool:
        """
        1. ê³„íš ìˆ˜ë¦½ (Planning)
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            memory: PPoGA ë©”ëª¨ë¦¬ ê°ì²´
            
        Returns:
            bool: ê³„íš ìˆ˜ë¦½ ì„±ê³µ ì—¬ë¶€
        """
        print(f"ğŸ§ Planner: ì§ˆë¬¸ ë¶„ì„ ë° ê³„íš ìˆ˜ë¦½ ì¤‘...")
        
        prompt = DECOMPOSE_PLAN_PROMPT.format(question=question)
        response, token_info = self._call_llm(prompt)
        memory.increment_llm_calls()
        
        try:
            # JSON ì‘ë‹µ íŒŒì‹±
            plan_data = json.loads(response)
            plan_steps = plan_data.get("plan", [])
            rationale = plan_data.get("rationale", "")
            
            if not plan_steps:
                print("âŒ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: ë¹ˆ ê³„íš")
                return False
            
            # ë©”ëª¨ë¦¬ì— ê³„íš ì €ì¥
            memory.add_plan(plan_steps, rationale)
            
            print(f"âœ… ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: {len(plan_steps)}ê°œ ë‹¨ê³„")
            for i, step in enumerate(plan_steps):
                print(f"   {i+1}. {step['description']}")
            
            return True
            
        except json.JSONDecodeError as e:
            print(f"âŒ ê³„íš íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì‘ë‹µ: {response}")
            return False
    
    def predict(self, current_step: PlanStep, memory: PPoGAMemory) -> str:
        """
        2. ì˜ˆì¸¡ (Prediction)
        
        Args:
            current_step: í˜„ì¬ ì‹¤í–‰í•  ê³„íš ë‹¨ê³„
            memory: PPoGA ë©”ëª¨ë¦¬ ê°ì²´
            
        Returns:
            str: ì˜ˆì¸¡ ê²°ê³¼
        """
        print(f"ğŸ”® Planner: ë‹¨ê³„ {current_step.id} ê²°ê³¼ ì˜ˆì¸¡ ì¤‘...")
        
        prompt = PREDICT_PROMPT.format(plan_step=current_step.description)
        response, token_info = self._call_llm(prompt)
        memory.increment_llm_calls()
        
        try:
            prediction_data = json.loads(response)
            prediction_text = f"ì„±ê³µ: {prediction_data.get('success_scenario', '')}, " \
                            f"ì‹¤íŒ¨: {prediction_data.get('failure_scenario', '')}, " \
                            f"ì‹ ë¢°ë„: {prediction_data.get('confidence', 'medium')}"
            
            print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {prediction_text}")
            return prediction_text
            
        except json.JSONDecodeError:
            print(f"âš ï¸ ì˜ˆì¸¡ íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ ì‚¬ìš©")
            return response
    
    def select_relations(self, entity_name: str, entity_id: str, 
                        available_relations: List[str], current_step: PlanStep) -> List[str]:
        """
        3A. íƒìƒ‰ ê²½ë¡œ ê²°ì • (ê´€ê³„ ì„ íƒ)
        
        Args:
            entity_name: ì—”í‹°í‹° ì´ë¦„
            entity_id: ì—”í‹°í‹° ID
            available_relations: ì‚¬ìš© ê°€ëŠ¥í•œ ê´€ê³„ ëª©ë¡
            current_step: í˜„ì¬ ê³„íš ë‹¨ê³„
            
        Returns:
            List[str]: ì„ íƒëœ ê´€ê³„ ëª©ë¡
        """
        print(f"ğŸ¯ Planner: {entity_name}ì— ëŒ€í•œ ê´€ê³„ ì„ íƒ ì¤‘...")
        
        # PoGì˜ extract_relation_prompt ì¬ì‚¬ìš©
        relations_str = "; ".join(available_relations)
        prompt = f"""í˜„ì¬ ê³„íš ë‹¨ê³„: {current_step.description}
ì—”í‹°í‹°: {entity_name}
ì‚¬ìš© ê°€ëŠ¥í•œ ê´€ê³„ë“¤: {relations_str}

ì´ ê³„íš ë‹¨ê³„ë¥¼ í•´ê²°í•˜ëŠ” ë° ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ê´€ê³„ë“¤ì„ ìµœëŒ€ 3ê°œê¹Œì§€ ì„ íƒí•˜ì„¸ìš”.
ì„ íƒëœ ê´€ê³„ë“¤ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”: ["relation1", "relation2"]"""
        
        response, token_info = self._call_llm(prompt)
        
        try:
            # ê°„ë‹¨í•œ íŒŒì‹± (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì¶”ì¶œ)
            if "[" in response and "]" in response:
                start = response.find("[")
                end = response.rfind("]") + 1
                relations_list = json.loads(response[start:end])
                print(f"âœ… ê´€ê³„ ì„ íƒ ì™„ë£Œ: {relations_list}")
                return relations_list
            else:
                # ì²« ë²ˆì§¸ ê´€ê³„ë§Œ ì„ íƒ
                selected = [available_relations[0]] if available_relations else []
                print(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨, ì²« ë²ˆì§¸ ê´€ê³„ ì„ íƒ: {selected}")
                return selected
                
        except Exception as e:
            print(f"âš ï¸ ê´€ê³„ ì„ íƒ ì˜¤ë¥˜: {e}, ì²« ë²ˆì§¸ ê´€ê³„ ì‚¬ìš©")
            return [available_relations[0]] if available_relations else []
    
    def think_and_evaluate(self, prediction: str, observation: str, 
                          current_step: PlanStep, memory: PPoGAMemory) -> str:
        """
        4. ì‚¬ê³  ë° í‰ê°€ (Thinking & Evaluation)
        
        Args:
            prediction: ì´ì „ ì˜ˆì¸¡
            observation: ì‹¤ì œ ê´€ì°° ê²°ê³¼
            current_step: í˜„ì¬ ê³„íš ë‹¨ê³„
            memory: PPoGA ë©”ëª¨ë¦¬ ê°ì²´
            
        Returns:
            str: ë‹¤ìŒ í–‰ë™ ('PROCEED', 'CORRECT_PATH', 'REPLAN', 'FINISH')
        """
        print(f"ğŸ¤” Planner: ê²°ê³¼ ë¶„ì„ ë° ë‹¤ìŒ í–‰ë™ ê²°ì • ì¤‘...")
        
        memory_summary = memory.get_memory_summary()
        
        prompt = f"""ì˜ˆì¸¡: {prediction}
ì‹¤ì œ ê´€ì°°: {observation}
í˜„ì¬ ë‹¨ê³„: {current_step.description}
ë©”ëª¨ë¦¬ ìš”ì•½: {memory_summary}

ì˜ˆì¸¡ê³¼ ì‹¤ì œ ê²°ê³¼ë¥¼ ë¹„êµí•˜ê³  ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ì„¸ìš”:
- PROCEED: ë‹¤ìŒ ê³„íš ë‹¨ê³„ë¡œ ì§„í–‰
- CORRECT_PATH: í˜„ì¬ ë‹¨ê³„ë¥¼ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„  
- REPLAN: ì „ì²´ ê³„íšì„ ì¬ìˆ˜ë¦½
- FINISH: ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì–»ì–´ ë‹µë³€ ê°€ëŠ¥

ë‹¤ìŒ í–‰ë™ì„ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{{"next_action": "PROCEED|CORRECT_PATH|REPLAN|FINISH", "reasoning": "ì´ìœ "}}"""
        
        response, token_info = self._call_llm(prompt)
        memory.increment_llm_calls()
        
        try:
            result = json.loads(response)
            next_action = result.get("next_action", "PROCEED")
            reasoning = result.get("reasoning", "")
            
            print(f"âœ… ë‹¤ìŒ í–‰ë™ ê²°ì •: {next_action}")
            print(f"   ì´ìœ : {reasoning}")
            
            # ì‚¬ê³  ë‚´ìš©ì„ ë©”ëª¨ë¦¬ì— ê¸°ë¡
            thought = f"ì˜ˆì¸¡ vs ì‹¤ì œ: {prediction[:50]}... vs {observation[:50]}... | ê²°ì •: {next_action} | ì´ìœ : {reasoning}"
            memory.update_cycle_thought(current_step.id, thought)
            
            return next_action
            
        except json.JSONDecodeError:
            print(f"âš ï¸ í‰ê°€ íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ PROCEED ì‚¬ìš©")
            return "PROCEED"
    
    def replan(self, question: str, memory: PPoGAMemory, failure_reason: str) -> bool:
        """
        5. ì „ëµì  ê³„íš ìˆ˜ì • (Strategic Replanning)
        
        Args:
            question: ì›ë˜ ì§ˆë¬¸
            memory: PPoGA ë©”ëª¨ë¦¬ ê°ì²´
            failure_reason: ì‹¤íŒ¨ ì´ìœ 
            
        Returns:
            bool: ì¬ê³„íš ì„±ê³µ ì—¬ë¶€
        """
        print(f"ğŸ”„ Planner: ì „ëµì  ì¬ê³„íš ìˆ˜í–‰ ì¤‘...")
        
        memory_summary = memory.get_memory_summary()
        failed_plan = [step.description for step in memory.strategy["overall_plan"]]
        
        prompt = f"""ì›ë˜ ì§ˆë¬¸: {question}
ì‹¤íŒ¨í•œ ê³„íš: {failed_plan}
ì‹¤íŒ¨ ì´ìœ : {failure_reason}
í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´: {memory_summary}

ì´ì „ ì‹¤íŒ¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” íš¨ê³¼ì ì¸ ìƒˆë¡œìš´ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

ìƒˆë¡œìš´ ê³„íšì„ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:
{{
    "plan": [
        {{"description": "ìƒˆë¡œìš´ ì²« ë²ˆì§¸ ë‹¨ê³„"}},
        {{"description": "ìƒˆë¡œìš´ ë‘ ë²ˆì§¸ ë‹¨ê³„"}}
    ],
    "rationale": "ì¬ê³„íšì˜ ê·¼ê±°ì™€ ì´ì „ ê³„íš ëŒ€ë¹„ ê°œì„ ì "
}}"""
        
        response, token_info = self._call_llm(prompt)
        memory.increment_llm_calls()
        
        try:
            plan_data = json.loads(response)
            plan_steps = plan_data.get("plan", [])
            rationale = plan_data.get("rationale", "")
            
            if not plan_steps:
                print("âŒ ì¬ê³„íš ì‹¤íŒ¨: ë¹ˆ ê³„íš")
                return False
            
            # ë©”ëª¨ë¦¬ì— ìƒˆë¡œìš´ ê³„íš ì €ì¥ (ê¸°ì¡´ ê³„íšì€ alternative_plansë¡œ ì´ë™)
            memory.add_plan(plan_steps, rationale)
            
            print(f"âœ… ì¬ê³„íš ì™„ë£Œ: {len(plan_steps)}ê°œ ë‹¨ê³„")
            for i, step in enumerate(plan_steps):
                print(f"   {i+1}. {step['description']}")
            
            return True
            
        except json.JSONDecodeError as e:
            print(f"âŒ ì¬ê³„íš íŒŒì‹± ì˜¤ë¥˜: {e}")
            return False
    
    def generate_final_answer(self, question: str, memory: PPoGAMemory) -> Dict[str, Any]:
        """
        6. ìµœì¢… ë‹µë³€ ìƒì„±
        
        Args:
            question: ì›ë˜ ì§ˆë¬¸
            memory: PPoGA ë©”ëª¨ë¦¬ ê°ì²´
            
        Returns:
            Dict[str, Any]: ìµœì¢… ë‹µë³€ ì •ë³´
        """
        print(f"ğŸ“ Planner: ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘...")
        
        knowledge_summary = {
            "entities_discovered": len(memory.knowledge["exploration_graph"]["nodes"]),
            "reasoning_paths": memory.knowledge["reasoning_paths"],
            "key_findings": list(memory.knowledge["exploration_graph"]["nodes"].keys())[:10]
        }
        
        prompt = FINAL_ANSWER_PROMPT.format(
            question=question,
            knowledge_summary=str(knowledge_summary)
        )
        
        response, token_info = self._call_llm(prompt)
        memory.increment_llm_calls()
        
        try:
            answer_data = json.loads(response)
            
            final_answer = {
                "answer": answer_data.get("answer", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
                "confidence": answer_data.get("confidence", "low"),
                "reasoning": answer_data.get("reasoning", ""),
                "memory_summary": memory.get_memory_summary()
            }
            
            print(f"âœ… ìµœì¢… ë‹µë³€ ìƒì„± ì™„ë£Œ")
            print(f"   ë‹µë³€: {final_answer['answer']}")
            print(f"   ì‹ ë¢°ë„: {final_answer['confidence']}")
            
            return final_answer
            
        except json.JSONDecodeError:
            print(f"âš ï¸ ë‹µë³€ íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ ì‚¬ìš©")
            return {
                "answer": response,
                "confidence": "low",
                "reasoning": "íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ ì›ë³¸ ì‘ë‹µ",
                "memory_summary": memory.get_memory_summary()
            }
